# Awesome OpenSound
Various Audio Process Baselines

## Task 1: Sound Event Detection and Localization

1. An improved Event-Independent Network for Polyphonic Sound Event Localization and Detection (2020). [Github](https://github.com/yinkalario/EIN-SELD) 
2. SELD-Net: Sound Event Localization and Detection of overlapping sources using convolutional recurrent neural network, IEEE Journal of Selected Topics in Signal Processing (JSTSP 2018). [Github](https://github.com/sharathadavanne/seld-dcase2020)

## Task 2: Structure from Sound

1. Sebastian Thrun, Affine Structure from Sound. NIPS 2005, [paper link](https://papers.nips.cc/paper/2005/file/a7a3d70c6d17a73140918996d03c014f-Paper.pdf)
2. Zhoutong Zhang et al. Shape and Material from Sound. NIPS 2017. [paper link](https://papers.nips.cc/paper/2017/file/f4552671f8909587cf485ea990207f3b-Paper.pdf)
3. Miranda et al. Structure from Sound with Incomplete Data. ICASSP 2018. [paper link](https://ieeexplore.ieee.org/document/8462559)
4. Arun Balajee Vasudevan et al. Semantic Object Prediction and Spatial Sound Super-Resolution with Binaural Sounds. ECCV 2020. [paper link](https://www.trace.ethz.ch/publications/2020/sound_perception/index.html)
5. Changan Chen et al. Audio-Visual Waypoints for Navigation.

## Task 3: Sound Generation

1. Wei Ping et al. WaveFlow: A Compact Flow-based Model for Raw Audio. ICML2020. [paper link](https://arxiv.org/pdf/1912.01219.pdf)

## Dataset

1. Google AudioSet, [link](https://research.google.com/audioset/)

## Tools

1. SoundSpaces, [link](http://vision.cs.utexas.edu/projects/audio_visual_navigation/)
2. Pyroomacoustics. [link](https://pyroomacoustics.readthedocs.io/en/pypi-release/index.html)

## Position Encoding

1. On Position Embeddings in BERT. [paper link](https://openreview.net/pdf?id=onxoVA9FxMw)

## Permutation Invariant Training

1. Dong Yu et al. Permutation Invariant Training of Deep Models for Speaker-Independent Multi-talker Speech Separation. [paper link](https://arxiv.org/abs/1607.00325)

## Learning from Sound Raw Waveforms

1. Neil Zeghidour et al., Learning Filterbanks from Raw Speech for Phone Recognition. ICASSP 2018. [paper link](https://arxiv.org/abs/1711.01161)
2. Neil,Zeghidour et al., LEAF: A Learnable Frontend for Audio Classification. ICLR 2021. [paper link](https://arxiv.org/abs/2101.08596)
3. Paul-Gauthier Noe et al., CGCNN: Complex Gabor Convolutional Neural Network on Raw Speech. 2020. [paper link](https://arxiv.org/abs/2002.04569)
4. Yi Luo, Nima Mesgarani, Conv-TasNet: Surpassing Ideal Time-Frequency Magnitude Masking for Speech Separation. IEEE/ACM Transactions on Audio, Speech and Language Processing. 2019. [paper link](https://arxiv.org/abs/1809.07454), [code](https://github.com/kaituoxu/Conv-TasNet).
5. Yuhang He et al. SoundDet: Polyphonic Moving Sound Event Detection and Localization from Raw Waveform. ICML21. [paper link](http://proceedings.mlr.press/v139/he21b/he21b.pdf)
6. Yuhang He et al. SoundDoA: Learn Sound Source Direction of Arrival and Semantics from Sound Raw Waveforms. Interspeech 22.

## Sound + Vision Cross-Modality Perception

1. R. Gao and K. Grauman, 2.5D Visual Sound. CVPR, 2019. [paper link](http://vision.cs.utexas.edu/projects/2.5D_visual_sound/)
2. Valentina Sanguineti, et al., Audio-Visual Localization by Synthetic Acoustic Image Generation. AAAI, 2021. [paper link](https://ojs.aaai.org/index.php/AAAI/article/view/16354)
3. Triantafyllos Afouras, et al., Self-Supervised Learning of Audio-Visual Objects from Video. ECCV, 2020. [paper link](https://arxiv.org/pdf/2008.04237.pdf)
4. Senthil Purushwalkam, et al., Audio-Visual Floorplan Reconstruction, ICCV  2021. [paper link](https://github.com/senthilps8/avmap)
5. Hu Di, Lichao Mou, Qingzhong Wang, Junyu Gao and Yuansheng Hua and Dejing Dou and Xiao Xiang Zhu, Ambient Sound Helps: Audivisual Crowd Counting in Extreme Conditions. arxiv preprint. 2020. [paper link](https://arxiv.org/pdf/2005.07097.pdf).
6. Zhenyu Tang et al., GWA: A Large High-Quality Acoustic Dataset for Audio Processing. SIGGRAPH 2022. [project site](https://gamma.umd.edu/pro/sound/gwa)

## Binaural Sound Generation,
1. Yichong, Leng, et al., BinauralGrad: A Two-Stage Conditional Diffusion Probabilistic Model for Binaural Audio Synthesis. ArXiv [paper link](https://arxiv.org/abs/2205.14807)
2. Alexander Richard, et al., Neural Synthesis of Binaural Speech From Mono Audio. ICLR 2021. [paper link](https://openreview.net/forum?id=uAX8q61EVRu)
3. Sijia Li et al., Binaural Audio Generating via Multi-Task Learning. ACM SIGGRAPH Asia. 2021. [project site](https://gamma.umd.edu/publication/835)

## Neural Audio Effect
1. Christian Steinmetz et al. Style transfer of audio effects with differentiable signal processing. Journal of the Audio Engineering Society (JAES). 2022. [paper link](https://www.christiansteinmetz.com/)

## Sound + Vision Researchers

1. Ruohan Gao, [webpage](https://ai.stanford.edu/~rhgao/)



# Awesome OpenSound
Various Audio Process Baselines

## Task 1: Sound Event Detection and Localization

1. An improved Event-Independent Network for Polyphonic Sound Event Localization and Detection (2020). [Github](https://github.com/yinkalario/EIN-SELD) 
2. SELD-Net: Sound Event Localization and Detection of overlapping sources using convolutional recurrent neural network, IEEE Journal of Selected Topics in Signal Processing (JSTSP 2018). [Github](https://github.com/sharathadavanne/seld-dcase2020)

## Task 2: Structure from Sound

1. Sebastian Thrun, Affine Structure from Sound. NIPS 2005, [paper link](https://papers.nips.cc/paper/2005/file/a7a3d70c6d17a73140918996d03c014f-Paper.pdf)
2. Zhoutong Zhang et al. Shape and Material from Sound. NIPS 2017. [paper link](https://papers.nips.cc/paper/2017/file/f4552671f8909587cf485ea990207f3b-Paper.pdf)
3. Miranda et al. Structure from Sound with Incomplete Data. ICASSP 2018. [paper link](https://ieeexplore.ieee.org/document/8462559)
4. Arun Balajee Vasudevan et al. Semantic Object Prediction and Spatial Sound Super-Resolution with Binaural Sounds. ECCV 2020. [paper link](https://www.trace.ethz.ch/publications/2020/sound_perception/index.html)
5. Changan Chen et al. Audio-Visual Waypoints for Navigation.

## Task 3: Sound Generation

1. Wei Ping et al. WaveFlow: A Compact Flow-based Model for Raw Audio. ICML2020. [paper link](https://arxiv.org/pdf/1912.01219.pdf)

## Dataset

1. Google AudioSet, [link](https://research.google.com/audioset/)

## Tools

1. SoundSpaces, [link](http://vision.cs.utexas.edu/projects/audio_visual_navigation/)
2. Pyroomacoustics. [link](https://pyroomacoustics.readthedocs.io/en/pypi-release/index.html)

## Position Encoding

1. On Position Embeddings in BERT. [paper link](https://openreview.net/pdf?id=onxoVA9FxMw)

## Permutation Invariant Training

1. Dong Yu et al. Permutation Invariant Training of Deep Models for Speaker-Independent Multi-talker Speech Separation. [paper link](https://arxiv.org/abs/1607.00325)

## Learning from Sound Raw Waveforms

1. Neil Zeghidour et al., Learning Filterbanks from Raw Speech for Phone Recognition. ICASSP 2018. [paper link](https://arxiv.org/abs/1711.01161)
2. Neil,Zeghidour et al., LEAF: A Learnable Frontend for Audio Classification. ICLR 2021. [paper link](https://arxiv.org/abs/2101.08596)
3. Paul-Gauthier Noe et al., CGCNN: Complex Gabor Convolutional Neural Network on Raw Speech. 2020. [paper link](https://arxiv.org/abs/2002.04569)
4. Yi Luo, Nima Mesgarani, Conv-TasNet: Surpassing Ideal Time-Frequency Magnitude Masking for Speech Separation. IEEE/ACM Transactions on Audio, Speech and Language Processing. 2019. [paper link](https://arxiv.org/abs/1809.07454), [code](https://github.com/kaituoxu/Conv-TasNet).
5. Yuhang He et al. SoundDet: Polyphonic Moving Sound Event Detection and Localization from Raw Waveform. ICML21. [paper link](http://proceedings.mlr.press/v139/he21b/he21b.pdf)

## Sound + Vision Cross-Modality Perception

1. R. Gao and K. Grauman, 2.5D Visual Sound. CVPR, 2019. [paper link](http://vision.cs.utexas.edu/projects/2.5D_visual_sound/)
2. Valentina Sanguineti, et al., Audio-Visual Localization by Synthetic Acoustic Image Generation. AAAI, 2021. [paper link](file:///Users/yuhhe/Downloads/16354-Article%20Text-19848-1-2-20210518.pdf)


## Sound + Vision Researchers

1. Ruohan Gao, [webpage](https://ai.stanford.edu/~rhgao/)


